Start:20220123_22_01_26

Seed Set: True , Seed :3
Namespace(batch_size=64, img_size=256, logdir='./log/20220123_22_01_26.log', lr=0.001, model='regnet_x_8gf', n_epochs=200, optim='SGD', pretrained=True, resume=False, root='./data')

Using cuda device

RegNet(
  (stem): SimpleStemIN(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (trunk_output): Sequential(
    (block1): AnyStage(
      (block1-0): ResBottleneckBlock(
        (proj): ConvNormActivation(
          (0): Conv2d(32, 80, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(32, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block1-1): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
    )
    (block2): AnyStage(
      (block2-0): ResBottleneckBlock(
        (proj): ConvNormActivation(
          (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block2-1): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block2-2): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block2-3): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block2-4): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
    )
    (block3): AnyStage(
      (block3-0): ResBottleneckBlock(
        (proj): ConvNormActivation(
          (0): Conv2d(240, 720, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(240, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-1): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-2): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-3): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-4): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-5): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-6): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-7): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-8): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-9): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-10): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-11): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-12): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-13): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
      (block3-14): ResBottleneckBlock(
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
    )
    (block4): AnyStage(
      (block4-0): ResBottleneckBlock(
        (proj): ConvNormActivation(
          (0): Conv2d(720, 1920, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (f): BottleneckTransform(
          (a): ConvNormActivation(
            (0): Conv2d(720, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (b): ConvNormActivation(
            (0): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (c): ConvNormActivation(
            (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (activation): ReLU(inplace=True)
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=1920, out_features=4, bias=True)
)
Train_loss: 1.906592  Train_acc: 0.228125  [1/200]
Train_loss: 1.904097  Train_acc: 0.223438  [2/200]
Train_loss: 1.896031  Train_acc: 0.221875  [3/200]
Train_loss: 1.890401  Train_acc: 0.223438  [4/200]
Train_loss: 1.877272  Train_acc: 0.227500  [5/200]
Train_loss: 1.866607  Train_acc: 0.237500  [6/200]
Train_loss: 1.843141  Train_acc: 0.258929  [7/200]
Train_loss: 1.820779  Train_acc: 0.277344  [8/200]
Train_loss: 1.798123  Train_acc: 0.300694  [9/200]
Train_loss: 1.768877  Train_acc: 0.328125  [10/200]
Train_loss: 1.747828  Train_acc: 0.351989  [11/200]
Train_loss: 1.721227  Train_acc: 0.371615  [12/200]
Train_loss: 1.689357  Train_acc: 0.395913  [13/200]
Train_loss: 1.648740  Train_acc: 0.420536  [14/200]
Train_loss: 1.595636  Train_acc: 0.444375  [15/200]
Train_loss: 1.543392  Train_acc: 0.469922  [16/200]
Train_loss: 1.516761  Train_acc: 0.486765  [17/200]
Train_loss: 1.450786  Train_acc: 0.506944  [18/200]
Train_loss: 1.404604  Train_acc: 0.525000  [19/200]
Train_loss: 1.334586  Train_acc: 0.542344  [20/200]
Train_loss: 1.257163  Train_acc: 0.561012  [21/200]
Train_loss: 1.171555  Train_acc: 0.579261  [22/200]
Train_loss: 1.108074  Train_acc: 0.595788  [23/200]
Train_loss: 1.058067  Train_acc: 0.611198  [24/200]
Train_loss: 0.985786  Train_acc: 0.626000  [25/200]
Train_loss: 0.917935  Train_acc: 0.640264  [26/200]
Train_loss: 0.878081  Train_acc: 0.653472  [27/200]
Train_loss: 0.858838  Train_acc: 0.665179  [28/200]
Train_loss: 0.806103  Train_acc: 0.676293  [29/200]
Train_loss: 0.768199  Train_acc: 0.686979  [30/200]
Train_loss: 0.739809  Train_acc: 0.697077  [31/200]
Train_loss: 0.721274  Train_acc: 0.706543  [32/200]
Train_loss: 0.698092  Train_acc: 0.715436  [33/200]
Train_loss: 0.675102  Train_acc: 0.723805  [34/200]
Train_loss: 0.645149  Train_acc: 0.731696  [35/200]
Train_loss: 0.638401  Train_acc: 0.739149  [36/200]
Train_loss: 0.633078  Train_acc: 0.746199  [37/200]
Train_loss: 0.605706  Train_acc: 0.752878  [38/200]
Train_loss: 0.599715  Train_acc: 0.759215  [39/200]
Train_loss: 0.587689  Train_acc: 0.765234  [40/200]
Train_loss: 0.590792  Train_acc: 0.770960  [41/200]
Train_loss: 0.579866  Train_acc: 0.776414  [42/200]
Train_loss: 0.570650  Train_acc: 0.781613  [43/200]
Train_loss: 0.572068  Train_acc: 0.786577  [44/200]
Train_loss: 0.562829  Train_acc: 0.791319  [45/200]
Train_loss: 0.566565  Train_acc: 0.795856  [46/200]
Train_loss: 0.568261  Train_acc: 0.800199  [47/200]
Train_loss: 0.551291  Train_acc: 0.804362  [48/200]
Train_loss: 0.542896  Train_acc: 0.808355  [49/200]
Train_loss: 0.544497  Train_acc: 0.812187  [50/200]
Train_loss: 0.544901  Train_acc: 0.815870  [51/200]
Train_loss: 0.538610  Train_acc: 0.819411  [52/200]
Train_loss: 0.539330  Train_acc: 0.822818  [53/200]
Train_loss: 0.534511  Train_acc: 0.826100  [54/200]
Train_loss: 0.534825  Train_acc: 0.829261  [55/200]
Train_loss: 0.539984  Train_acc: 0.832310  [56/200]
Train_loss: 0.530691  Train_acc: 0.835252  [57/200]
Train_loss: 0.534257  Train_acc: 0.838093  [58/200]
Train_loss: 0.536153  Train_acc: 0.840837  [59/200]
Train_loss: 0.528612  Train_acc: 0.843490  [60/200]
Train_loss: 0.529131  Train_acc: 0.846055  [61/200]
Train_loss: 0.524140  Train_acc: 0.848538  [62/200]
Train_loss: 0.528172  Train_acc: 0.850942  [63/200]
Train_loss: 0.525148  Train_acc: 0.853271  [64/200]
Train_loss: 0.520371  Train_acc: 0.855529  [65/200]
Train_loss: 0.521517  Train_acc: 0.857718  [66/200]
Train_loss: 0.524123  Train_acc: 0.859841  [67/200]
Train_loss: 0.522534  Train_acc: 0.861903  [68/200]
Train_loss: 0.522705  Train_acc: 0.863904  [69/200]
Train_loss: 0.520751  Train_acc: 0.865848  [70/200]
Train_loss: 0.519665  Train_acc: 0.867738  [71/200]
Train_loss: 0.525475  Train_acc: 0.869575  [72/200]
Train_loss: 0.520434  Train_acc: 0.871361  [73/200]
Train_loss: 0.520994  Train_acc: 0.873100  [74/200]
Train_loss: 0.516511  Train_acc: 0.874792  [75/200]
Train_loss: 0.517216  Train_acc: 0.876439  [76/200]
Train_loss: 0.520429  Train_acc: 0.878044  [77/200]
Train_loss: 0.515948  Train_acc: 0.879607  [78/200]
Train_loss: 0.517015  Train_acc: 0.881131  [79/200]
Train_loss: 0.515536  Train_acc: 0.882617  [80/200]
Train_loss: 0.516177  Train_acc: 0.884066  [81/200]
Train_loss: 0.515815  Train_acc: 0.885480  [82/200]
Train_loss: 0.517421  Train_acc: 0.886860  [83/200]
Train_loss: 0.513801  Train_acc: 0.888207  [84/200]
Train_loss: 0.513483  Train_acc: 0.889522  [85/200]
Train_loss: 0.513581  Train_acc: 0.890807  [86/200]
Train_loss: 0.511964  Train_acc: 0.892062  [87/200]
Train_loss: 0.513024  Train_acc: 0.893288  [88/200]
Train_loss: 0.514082  Train_acc: 0.894487  [89/200]
Train_loss: 0.512500  Train_acc: 0.895660  [90/200]
Train_loss: 0.514951  Train_acc: 0.896806  [91/200]
Train_loss: 0.511476  Train_acc: 0.897928  [92/200]
Train_loss: 0.513507  Train_acc: 0.899026  [93/200]
Train_loss: 0.513515  Train_acc: 0.900100  [94/200]
Train_loss: 0.512111  Train_acc: 0.901151  [95/200]
Train_loss: 0.514087  Train_acc: 0.902181  [96/200]
Train_loss: 0.511852  Train_acc: 0.903189  [97/200]
Train_loss: 0.513232  Train_acc: 0.904177  [98/200]
Train_loss: 0.511052  Train_acc: 0.905145  [99/200]
Train_loss: 0.513491  Train_acc: 0.906094  [100/200]
Train_loss: 0.510044  Train_acc: 0.907024  [101/200]
Train_loss: 0.512226  Train_acc: 0.907935  [102/200]
Train_loss: 0.512955  Train_acc: 0.908829  [103/200]
Train_loss: 0.512701  Train_acc: 0.909706  [104/200]
Train_loss: 0.510802  Train_acc: 0.910565  [105/200]
Train_loss: 0.511219  Train_acc: 0.911409  [106/200]
Train_loss: 0.508528  Train_acc: 0.912237  [107/200]
Train_loss: 0.510047  Train_acc: 0.913050  [108/200]
Train_loss: 0.511298  Train_acc: 0.913847  [109/200]
Train_loss: 0.509616  Train_acc: 0.914631  [110/200]
Train_loss: 0.511470  Train_acc: 0.915400  [111/200]
Train_loss: 0.512016  Train_acc: 0.916155  [112/200]
Train_loss: 0.511039  Train_acc: 0.916897  [113/200]
Train_loss: 0.509318  Train_acc: 0.917626  [114/200]
Train_loss: 0.509956  Train_acc: 0.918342  [115/200]
Train_loss: 0.509793  Train_acc: 0.919046  [116/200]
Train_loss: 0.509613  Train_acc: 0.919738  [117/200]
Train_loss: 0.509857  Train_acc: 0.920418  [118/200]
Train_loss: 0.511633  Train_acc: 0.921087  [119/200]
Train_loss: 0.509869  Train_acc: 0.921745  [120/200]
Train_loss: 0.510904  Train_acc: 0.922392  [121/200]
Train_loss: 0.508873  Train_acc: 0.923028  [122/200]
Train_loss: 0.508364  Train_acc: 0.923653  [123/200]
Train_loss: 0.509536  Train_acc: 0.924269  [124/200]
Train_loss: 0.509053  Train_acc: 0.924875  [125/200]
Train_loss: 0.509234  Train_acc: 0.925471  [126/200]
Train_loss: 0.507903  Train_acc: 0.926058  [127/200]
Train_loss: 0.509819  Train_acc: 0.926636  [128/200]
Train_loss: 0.508157  Train_acc: 0.927204  [129/200]
Train_loss: 0.508553  Train_acc: 0.927764  [130/200]
Train_loss: 0.510007  Train_acc: 0.928316  [131/200]
Train_loss: 0.508155  Train_acc: 0.928859  [132/200]
Train_loss: 0.509335  Train_acc: 0.929394  [133/200]
Train_loss: 0.508949  Train_acc: 0.929921  [134/200]
Train_loss: 0.510681  Train_acc: 0.930440  [135/200]
Train_loss: 0.510750  Train_acc: 0.930951  [136/200]
Train_loss: 0.510985  Train_acc: 0.931455  [137/200]
Train_loss: 0.511029  Train_acc: 0.931952  [138/200]
Train_loss: 0.508157  Train_acc: 0.932442  [139/200]
Train_loss: 0.508600  Train_acc: 0.932924  [140/200]
Train_loss: 0.508657  Train_acc: 0.933400  [141/200]
Train_loss: 0.508331  Train_acc: 0.933869  [142/200]
Train_loss: 0.510336  Train_acc: 0.934331  [143/200]
Train_loss: 0.508776  Train_acc: 0.934787  [144/200]
Train_loss: 0.507830  Train_acc: 0.935237  [145/200]
Train_loss: 0.508183  Train_acc: 0.935681  [146/200]
Train_loss: 0.508767  Train_acc: 0.936118  [147/200]
Train_loss: 0.507839  Train_acc: 0.936550  [148/200]
Train_loss: 0.508385  Train_acc: 0.936976  [149/200]
Train_loss: 0.507664  Train_acc: 0.937396  [150/200]
Train_loss: 0.507543  Train_acc: 0.937810  [151/200]
Train_loss: 0.507962  Train_acc: 0.938220  [152/200]
Train_loss: 0.508870  Train_acc: 0.938623  [153/200]
Train_loss: 0.509494  Train_acc: 0.939022  [154/200]
Train_loss: 0.508930  Train_acc: 0.939415  [155/200]
Train_loss: 0.509506  Train_acc: 0.939804  [156/200]
Train_loss: 0.508923  Train_acc: 0.940187  [157/200]
Train_loss: 0.508998  Train_acc: 0.940566  [158/200]
Train_loss: 0.507066  Train_acc: 0.940939  [159/200]
Train_loss: 0.508114  Train_acc: 0.941309  [160/200]
Train_loss: 0.507790  Train_acc: 0.941673  [161/200]
Train_loss: 0.510172  Train_acc: 0.942033  [162/200]
Train_loss: 0.508128  Train_acc: 0.942389  [163/200]
Train_loss: 0.508634  Train_acc: 0.942740  [164/200]
Train_loss: 0.507761  Train_acc: 0.943087  [165/200]
Train_loss: 0.508523  Train_acc: 0.943430  [166/200]
Train_loss: 0.507685  Train_acc: 0.943769  [167/200]
Train_loss: 0.508997  Train_acc: 0.944103  [168/200]
Train_loss: 0.507971  Train_acc: 0.944434  [169/200]
Train_loss: 0.507881  Train_acc: 0.944761  [170/200]
Train_loss: 0.508053  Train_acc: 0.945084  [171/200]
Train_loss: 0.508520  Train_acc: 0.945403  [172/200]
Train_loss: 0.507336  Train_acc: 0.945719  [173/200]
Train_loss: 0.509145  Train_acc: 0.946031  [174/200]
Train_loss: 0.507946  Train_acc: 0.946339  [175/200]
Train_loss: 0.507465  Train_acc: 0.946644  [176/200]
Train_loss: 0.507829  Train_acc: 0.946946  [177/200]
Train_loss: 0.508405  Train_acc: 0.947244  [178/200]
Train_loss: 0.508053  Train_acc: 0.947538  [179/200]
Train_loss: 0.507720  Train_acc: 0.947830  [180/200]
Train_loss: 0.507288  Train_acc: 0.948118  [181/200]
Train_loss: 0.508194  Train_acc: 0.948403  [182/200]
Train_loss: 0.506907  Train_acc: 0.948685  [183/200]
Train_loss: 0.506971  Train_acc: 0.948964  [184/200]
Train_loss: 0.508282  Train_acc: 0.949240  [185/200]
Train_loss: 0.507373  Train_acc: 0.949513  [186/200]
Train_loss: 0.507662  Train_acc: 0.949783  [187/200]
Train_loss: 0.508617  Train_acc: 0.950050  [188/200]
Train_loss: 0.507072  Train_acc: 0.950314  [189/200]
Train_loss: 0.507787  Train_acc: 0.950576  [190/200]
Train_loss: 0.509121  Train_acc: 0.950834  [191/200]
Train_loss: 0.507335  Train_acc: 0.951090  [192/200]
Train_loss: 0.508828  Train_acc: 0.951344  [193/200]
Train_loss: 0.509125  Train_acc: 0.951595  [194/200]
Train_loss: 0.508685  Train_acc: 0.951843  [195/200]
Train_loss: 0.510347  Train_acc: 0.952089  [196/200]
Train_loss: 0.507341  Train_acc: 0.952332  [197/200]
Train_loss: 0.508926  Train_acc: 0.952573  [198/200]
Train_loss: 0.510559  Train_acc: 0.952811  [199/200]
Train_loss: 0.507571  Train_acc: 0.953047  [200/200]
Test_acc: 0.612500

End:20220123_22_20_23
Implementation time:18m 56s

