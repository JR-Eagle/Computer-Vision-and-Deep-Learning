Start:20220123_20_34_13

Seed Set: True , Seed :3
Namespace(batch_size=64, img_size=256, logdir='./log/20220123_20_34_13.log', lr=0.001, model='alexnet', n_epochs=200, optim='SGD', pretrained=True, resume=False, root='./data')

Using cuda device

AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=4, bias=True)
  )
)
Train_loss: 1.970993  Train_acc: 0.296875  [1/200]
Train_loss: 1.811610  Train_acc: 0.326562  [2/200]
Train_loss: 1.754520  Train_acc: 0.366667  [3/200]
Train_loss: 1.656432  Train_acc: 0.393750  [4/200]
Train_loss: 1.566907  Train_acc: 0.423750  [5/200]
Train_loss: 1.472704  Train_acc: 0.448437  [6/200]
Train_loss: 1.383476  Train_acc: 0.475000  [7/200]
Train_loss: 1.384860  Train_acc: 0.492578  [8/200]
Train_loss: 1.393209  Train_acc: 0.507292  [9/200]
Train_loss: 1.394036  Train_acc: 0.520000  [10/200]
Train_loss: 1.146006  Train_acc: 0.540057  [11/200]
Train_loss: 1.204533  Train_acc: 0.553385  [12/200]
Train_loss: 1.214464  Train_acc: 0.564663  [13/200]
Train_loss: 0.965276  Train_acc: 0.583482  [14/200]
Train_loss: 0.966230  Train_acc: 0.598958  [15/200]
Train_loss: 1.413503  Train_acc: 0.601758  [16/200]
Train_loss: 0.899981  Train_acc: 0.615257  [17/200]
Train_loss: 1.018329  Train_acc: 0.623958  [18/200]
Train_loss: 0.802780  Train_acc: 0.638322  [19/200]
Train_loss: 0.908746  Train_acc: 0.648594  [20/200]
Train_loss: 0.924891  Train_acc: 0.656994  [21/200]
Train_loss: 0.671133  Train_acc: 0.670028  [22/200]
Train_loss: 0.761132  Train_acc: 0.679484  [23/200]
Train_loss: 0.602771  Train_acc: 0.691927  [24/200]
Train_loss: 0.600262  Train_acc: 0.703125  [25/200]
Train_loss: 0.573053  Train_acc: 0.713702  [26/200]
Train_loss: 0.592807  Train_acc: 0.723264  [27/200]
Train_loss: 0.785083  Train_acc: 0.729018  [28/200]
Train_loss: 0.644212  Train_acc: 0.736746  [29/200]
Train_loss: 0.536667  Train_acc: 0.745417  [30/200]
Train_loss: 0.531468  Train_acc: 0.753528  [31/200]
Train_loss: 0.523935  Train_acc: 0.761133  [32/200]
Train_loss: 0.519649  Train_acc: 0.768371  [33/200]
Train_loss: 0.520854  Train_acc: 0.775000  [34/200]
Train_loss: 0.518241  Train_acc: 0.781429  [35/200]
Train_loss: 0.520755  Train_acc: 0.787240  [36/200]
Train_loss: 0.515712  Train_acc: 0.792905  [37/200]
Train_loss: 0.508235  Train_acc: 0.798355  [38/200]
Train_loss: 0.511102  Train_acc: 0.803526  [39/200]
Train_loss: 0.512595  Train_acc: 0.808359  [40/200]
Train_loss: 0.507383  Train_acc: 0.813034  [41/200]
Train_loss: 0.506644  Train_acc: 0.817485  [42/200]
Train_loss: 0.502982  Train_acc: 0.821730  [43/200]
Train_loss: 0.503354  Train_acc: 0.825781  [44/200]
Train_loss: 0.500183  Train_acc: 0.829653  [45/200]
Train_loss: 0.503834  Train_acc: 0.833356  [46/200]
Train_loss: 0.504408  Train_acc: 0.836902  [47/200]
Train_loss: 0.501727  Train_acc: 0.840299  [48/200]
Train_loss: 0.499877  Train_acc: 0.843559  [49/200]
Train_loss: 0.500064  Train_acc: 0.846688  [50/200]
Train_loss: 0.505140  Train_acc: 0.849632  [51/200]
Train_loss: 0.501720  Train_acc: 0.852524  [52/200]
Train_loss: 0.498880  Train_acc: 0.855307  [53/200]
Train_loss: 0.500441  Train_acc: 0.857986  [54/200]
Train_loss: 0.502609  Train_acc: 0.860511  [55/200]
Train_loss: 0.500045  Train_acc: 0.863002  [56/200]
Train_loss: 0.501507  Train_acc: 0.865406  [57/200]
Train_loss: 0.498392  Train_acc: 0.867726  [58/200]
Train_loss: 0.498460  Train_acc: 0.869968  [59/200]
Train_loss: 0.501427  Train_acc: 0.872135  [60/200]
Train_loss: 0.503948  Train_acc: 0.874180  [61/200]
Train_loss: 0.499925  Train_acc: 0.876210  [62/200]
Train_loss: 0.499218  Train_acc: 0.878175  [63/200]
Train_loss: 0.497525  Train_acc: 0.880078  [64/200]
Train_loss: 0.498074  Train_acc: 0.881923  [65/200]
Train_loss: 0.497288  Train_acc: 0.883712  [66/200]
Train_loss: 0.496738  Train_acc: 0.885448  [67/200]
Train_loss: 0.496958  Train_acc: 0.887132  [68/200]
Train_loss: 0.496516  Train_acc: 0.888768  [69/200]
Train_loss: 0.496844  Train_acc: 0.890357  [70/200]
Train_loss: 0.498163  Train_acc: 0.891901  [71/200]
Train_loss: 0.496852  Train_acc: 0.893403  [72/200]
Train_loss: 0.498290  Train_acc: 0.894863  [73/200]
Train_loss: 0.497428  Train_acc: 0.896284  [74/200]
Train_loss: 0.496980  Train_acc: 0.897667  [75/200]
Train_loss: 0.496816  Train_acc: 0.899013  [76/200]
Train_loss: 0.495970  Train_acc: 0.900325  [77/200]
Train_loss: 0.497424  Train_acc: 0.901603  [78/200]
Train_loss: 0.497146  Train_acc: 0.902848  [79/200]
Train_loss: 0.496142  Train_acc: 0.904062  [80/200]
Train_loss: 0.495897  Train_acc: 0.905247  [81/200]
Train_loss: 0.497052  Train_acc: 0.906402  [82/200]
Train_loss: 0.502293  Train_acc: 0.907492  [83/200]
Train_loss: 0.499621  Train_acc: 0.908594  [84/200]
Train_loss: 0.496708  Train_acc: 0.909669  [85/200]
Train_loss: 0.495325  Train_acc: 0.910719  [86/200]
Train_loss: 0.495482  Train_acc: 0.911746  [87/200]
Train_loss: 0.499149  Train_acc: 0.912749  [88/200]
Train_loss: 0.498585  Train_acc: 0.913729  [89/200]
Train_loss: 0.496153  Train_acc: 0.914687  [90/200]
Train_loss: 0.496001  Train_acc: 0.915625  [91/200]
Train_loss: 0.496299  Train_acc: 0.916542  [92/200]
Train_loss: 0.495656  Train_acc: 0.917440  [93/200]
Train_loss: 0.495534  Train_acc: 0.918318  [94/200]
Train_loss: 0.495231  Train_acc: 0.919178  [95/200]
Train_loss: 0.496638  Train_acc: 0.920020  [96/200]
Train_loss: 0.495270  Train_acc: 0.920844  [97/200]
Train_loss: 0.495122  Train_acc: 0.921652  [98/200]
Train_loss: 0.496439  Train_acc: 0.922443  [99/200]
Train_loss: 0.496181  Train_acc: 0.923219  [100/200]
Train_loss: 0.495388  Train_acc: 0.923979  [101/200]
Train_loss: 0.496770  Train_acc: 0.924724  [102/200]
Train_loss: 0.496369  Train_acc: 0.925455  [103/200]
Train_loss: 0.495646  Train_acc: 0.926172  [104/200]
Train_loss: 0.495376  Train_acc: 0.926875  [105/200]
Train_loss: 0.495914  Train_acc: 0.927565  [106/200]
Train_loss: 0.495532  Train_acc: 0.928242  [107/200]
Train_loss: 0.495226  Train_acc: 0.928906  [108/200]
Train_loss: 0.495724  Train_acc: 0.929558  [109/200]
Train_loss: 0.495557  Train_acc: 0.930199  [110/200]
Train_loss: 0.495140  Train_acc: 0.930828  [111/200]
Train_loss: 0.497703  Train_acc: 0.931445  [112/200]
Train_loss: 0.495980  Train_acc: 0.932052  [113/200]
Train_loss: 0.496100  Train_acc: 0.932648  [114/200]
Train_loss: 0.496148  Train_acc: 0.933234  [115/200]
Train_loss: 0.495509  Train_acc: 0.933809  [116/200]
Train_loss: 0.497088  Train_acc: 0.934375  [117/200]
Train_loss: 0.495852  Train_acc: 0.934931  [118/200]
Train_loss: 0.497189  Train_acc: 0.935478  [119/200]
Train_loss: 0.496425  Train_acc: 0.936016  [120/200]
Train_loss: 0.495153  Train_acc: 0.936544  [121/200]
Train_loss: 0.495253  Train_acc: 0.937065  [122/200]
Train_loss: 0.494489  Train_acc: 0.937576  [123/200]
Train_loss: 0.495434  Train_acc: 0.938080  [124/200]
Train_loss: 0.496979  Train_acc: 0.938575  [125/200]
Train_loss: 0.495795  Train_acc: 0.939063  [126/200]
Train_loss: 0.495916  Train_acc: 0.939542  [127/200]
Train_loss: 0.494962  Train_acc: 0.940015  [128/200]
Train_loss: 0.495366  Train_acc: 0.940480  [129/200]
Train_loss: 0.495295  Train_acc: 0.940937  [130/200]
Train_loss: 0.495328  Train_acc: 0.941388  [131/200]
Train_loss: 0.495220  Train_acc: 0.941832  [132/200]
Train_loss: 0.495694  Train_acc: 0.942270  [133/200]
Train_loss: 0.494668  Train_acc: 0.942701  [134/200]
Train_loss: 0.495428  Train_acc: 0.943125  [135/200]
Train_loss: 0.495026  Train_acc: 0.943543  [136/200]
Train_loss: 0.495025  Train_acc: 0.943955  [137/200]
Train_loss: 0.495163  Train_acc: 0.944361  [138/200]
Train_loss: 0.494773  Train_acc: 0.944762  [139/200]
Train_loss: 0.495690  Train_acc: 0.945156  [140/200]
Train_loss: 0.495135  Train_acc: 0.945545  [141/200]
Train_loss: 0.494989  Train_acc: 0.945929  [142/200]
Train_loss: 0.495111  Train_acc: 0.946307  [143/200]
Train_loss: 0.495684  Train_acc: 0.946680  [144/200]
Train_loss: 0.496073  Train_acc: 0.947047  [145/200]
Train_loss: 0.494711  Train_acc: 0.947410  [146/200]
Train_loss: 0.495360  Train_acc: 0.947768  [147/200]
Train_loss: 0.494757  Train_acc: 0.948121  [148/200]
Train_loss: 0.494587  Train_acc: 0.948469  [149/200]
Train_loss: 0.495747  Train_acc: 0.948812  [150/200]
Train_loss: 0.495520  Train_acc: 0.949151  [151/200]
Train_loss: 0.498435  Train_acc: 0.949486  [152/200]
Train_loss: 0.495064  Train_acc: 0.949816  [153/200]
Train_loss: 0.496340  Train_acc: 0.950142  [154/200]
Train_loss: 0.495485  Train_acc: 0.950464  [155/200]
Train_loss: 0.494719  Train_acc: 0.950781  [156/200]
Train_loss: 0.495235  Train_acc: 0.951095  [157/200]
Train_loss: 0.495809  Train_acc: 0.951404  [158/200]
Train_loss: 0.495102  Train_acc: 0.951710  [159/200]
Train_loss: 0.495693  Train_acc: 0.952012  [160/200]
Train_loss: 0.495137  Train_acc: 0.952310  [161/200]
Train_loss: 0.494843  Train_acc: 0.952604  [162/200]
Train_loss: 0.494662  Train_acc: 0.952895  [163/200]
Train_loss: 0.494775  Train_acc: 0.953182  [164/200]
Train_loss: 0.494679  Train_acc: 0.953466  [165/200]
Train_loss: 0.496008  Train_acc: 0.953746  [166/200]
Train_loss: 0.495041  Train_acc: 0.954023  [167/200]
Train_loss: 0.494997  Train_acc: 0.954297  [168/200]
Train_loss: 0.494946  Train_acc: 0.954567  [169/200]
Train_loss: 0.495165  Train_acc: 0.954835  [170/200]
Train_loss: 0.494746  Train_acc: 0.955099  [171/200]
Train_loss: 0.494986  Train_acc: 0.955360  [172/200]
Train_loss: 0.495650  Train_acc: 0.955618  [173/200]
Train_loss: 0.495445  Train_acc: 0.955873  [174/200]
Train_loss: 0.494798  Train_acc: 0.956125  [175/200]
Train_loss: 0.495029  Train_acc: 0.956374  [176/200]
Train_loss: 0.495166  Train_acc: 0.956621  [177/200]
Train_loss: 0.494803  Train_acc: 0.956864  [178/200]
Train_loss: 0.498352  Train_acc: 0.957088  [179/200]
Train_loss: 0.495043  Train_acc: 0.957326  [180/200]
Train_loss: 0.495057  Train_acc: 0.957562  [181/200]
Train_loss: 0.494710  Train_acc: 0.957795  [182/200]
Train_loss: 0.495313  Train_acc: 0.958026  [183/200]
Train_loss: 0.494795  Train_acc: 0.958254  [184/200]
Train_loss: 0.494893  Train_acc: 0.958480  [185/200]
Train_loss: 0.495290  Train_acc: 0.958703  [186/200]
Train_loss: 0.495340  Train_acc: 0.958924  [187/200]
Train_loss: 0.495487  Train_acc: 0.959142  [188/200]
Train_loss: 0.495293  Train_acc: 0.959358  [189/200]
Train_loss: 0.496023  Train_acc: 0.959572  [190/200]
Train_loss: 0.495707  Train_acc: 0.959784  [191/200]
Train_loss: 0.495047  Train_acc: 0.959993  [192/200]
Train_loss: 0.496690  Train_acc: 0.960201  [193/200]
Train_loss: 0.495974  Train_acc: 0.960406  [194/200]
Train_loss: 0.495186  Train_acc: 0.960609  [195/200]
Train_loss: 0.494905  Train_acc: 0.960810  [196/200]
Train_loss: 0.496179  Train_acc: 0.961009  [197/200]
Train_loss: 0.494661  Train_acc: 0.961206  [198/200]
Train_loss: 0.495496  Train_acc: 0.961401  [199/200]
Train_loss: 0.495460  Train_acc: 0.961594  [200/200]
Test_acc: 0.612500

End:20220123_20_42_46
Implementation time:8m 33s

